{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "f(R) gravity emulator: for fast generation of P_mg/P_lcdm\n",
    "\n",
    "\n",
    "Requires the following installations:\n",
    "\n",
    "1. gpflow\n",
    "2. scipy\n",
    "3. sklearn \n",
    "\"\"\"\n",
    "\n",
    "##### Generic packages ###############\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "import gpflow\n",
    "import scipy.signal\n",
    "\n",
    "\n",
    "####### PLOTTING SETTINGS #####\n",
    "from itertools import cycle\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import gridspec\n",
    "\n",
    "\n",
    "# plt.rc('text', usetex=True)  # Slower\n",
    "plt.rc('axes',labelsize= 10)\n",
    "plt.rc('xtick', labelsize='x-large')\n",
    "plt.rc('ytick', labelsize='x-large')\n",
    "\n",
    "\n",
    "########## R imports ############\n",
    "# RcppCNPy = importr('RcppCNPy')\n",
    "# RcppCNPy.chooseCRANmirror(ind=1) # select the first mirror in the list\n",
    "## There are other importr calls in PCA and GP functions\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# PARAMETERS ##############################\n",
    "\n",
    "# dataDir = \"./Data/Fixedn/\" ## Data folder\n",
    "# modelDir = \"./Models/Fixedn/\" ## Data folder\n",
    "# plotsDir = \"./Plots/Fixedn/\" ## Data folder\n",
    "\n",
    "# dataDir = \"./Data/Fixedn_val/\" ## Data folder\n",
    "# modelDir = \"./Models/Fixedn_val/\" ## Data folder\n",
    "# plotsDir = \"./Plots/Fixedn_val/\" ## Data folder\n",
    "\n",
    "\n",
    "dataDir = \"./Data/Fixedn_val_latest/\" ## Data folder\n",
    "modelDir = \"./Models/Fixedn_val_latest/\" ## Data folder\n",
    "plotsDir = \"./Plots/Fixedn_val_latest/\" ## Data folder\n",
    "\n",
    "\n",
    "nRankMax = [2, 4, 5, 6, 7, 8, 12, 16, 32][3]  ## Number of basis vectors in truncated PCA\n",
    "## Increasing nRankMax will increase emulation precision (asymptotically), but reduce the speed\n",
    "# del_idx = []  ## Random holdouts (not used in training, reserved for validation) \n",
    "del_idx = [50, 51, 52, 53, 54]# [8, 12, 3, 43] ## Random holdouts (not used in training, reserved for validation) \n",
    "# DONOT use these: (array([22, 15, 19, 20, 35]), array([27, 34, 30, 29, 14])) -- edge cases\n",
    "snap_ID = 97\n",
    "\n",
    "\n",
    "############################# PARAMETERS ##############################\n",
    "\n",
    "\n",
    "fileIn = dataDir + 'ratiosbinsnew_' + str(snap_ID) + '.txt'\n",
    "# paramIn = dataDir + 'mg_log_val.design'\n",
    "paramIn = dataDir + 'mg_log_val_2.design'\n",
    "\n",
    "\n",
    "\n",
    "az = np.loadtxt(dataDir + 'timestepsCOLA.txt', skiprows=1) \n",
    "fileIn = dataDir + 'ratiosbins_' + str(snap_ID) + '.txt'\n",
    "z_ID = az[snap_ID, 1]\n",
    "\n",
    "\n",
    "fileIn = dataDir + 'ratiosbinsnew_' + str(snap_ID) + '.txt'\n",
    "\n",
    "GPmodel = modelDir + 'nCorrLogfixedGP_smooth_rank' + str(nRankMax) + 'snap' + str(snap_ID)  ## Double and single quotes are necessary\n",
    "PCAmodel = modelDir + 'nCorrLogfixedPCA_smooth_rank' + str(nRankMax) + 'snap' + str(snap_ID)  ## Double and single quotes are necessary\n",
    "\n",
    "print(GPmodel)\n",
    "################################# I/O #################################\n",
    "\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############################# PARAMETERS ##############################\n",
    "# nRankMax = 4 ## Number of basis vectors in truncated PCA\n",
    "# del_idx =  [5, 25, 4, 42]  ## holdouts for testing\n",
    "# snap_ID = 97\n",
    "# ############################# INPUT FILES ##############################\n",
    "\n",
    "# plotsDir = \"./Plots/\" ## Data folder\n",
    "# # dataDir = \"./Data/Emulator_data/\" ## Data folder\n",
    "# dataDir = \"./Data/Emulator213bins/\" ## Data folder\n",
    "\n",
    "# paramIn = dataDir + 'mg.design'  ## parameter file\n",
    "\n",
    "\n",
    "\n",
    "# az = np.loadtxt(dataDir + 'timestepsCOLA.txt', skiprows=1) \n",
    "# fileIn = dataDir + 'ratiosbins_' + str(snap_ID) + '.txt'\n",
    "# GPmodel = '\"GP_model_213Smooth_rank' + str(nRankMax) + 'snap' + str(snap_ID) +'.RData\"'  ## Double and single quotes are necessary\n",
    "# ## DELETE the GPmodels or provide a new name if you want a new calculation\n",
    "# # num_holdout = 4\n",
    "# print(GPmodel)\n",
    "# ################################# I/O #################################\n",
    "\n",
    "\n",
    "# loadFile = np.loadtxt(fileIn)\n",
    "# PmPl_all = loadFile[:, 1:].T\n",
    "# kvals = loadFile[:,0]\n",
    "# parameter_array_all = np.loadtxt(paramIn)\n",
    "# z_ID = az[snap_ID, 1]\n",
    "\n",
    "# ########################## Deleting hold-out from training ##############\n",
    "\n",
    "\n",
    "# PmPl = np.delete(PmPl_all, del_idx, axis = 0)\n",
    "# parameter_array = np.delete(parameter_array_all, del_idx, axis = 0)\n",
    "\n",
    "\n",
    "# ####################### porting to R backend #######################\n",
    "\n",
    "# #### adding smoothing filter ########\n",
    "\n",
    "# import scipy.signal\n",
    "# yhat = scipy.signal.savgol_filter(PmPl[:,:], 51, 3) # window size 51, polynomial order 3\n",
    "\n",
    "# ####################################\n",
    "\n",
    "\n",
    "\n",
    "# nr, nc = yhat.shape\n",
    "# y_train = ro.r.matrix(yhat, nrow=nr, ncol=nc)\n",
    "\n",
    "\n",
    "# # nr, nc = PmPl[:,:].shape\n",
    "# # y_train = ro.r.matrix(PmPl[:,:], nrow=nr, ncol=nc)\n",
    "# ro.r.assign(\"y_train2\", y_train)\n",
    "# r('dim(y_train2)')\n",
    "\n",
    "# nr, nc = parameter_array[:,:].shape\n",
    "# u_train = ro.r.matrix(parameter_array[:,:], nrow=nr, ncol=nc)\n",
    "# ro.r.assign(\"u_train2\", u_train)\n",
    "# r('dim(u_train2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadFile = np.loadtxt(fileIn)\n",
    "PmPl_all = loadFile[:, 1:].T\n",
    "kvals = loadFile[:,0]\n",
    "\n",
    "parameter_array_all = np.loadtxt(paramIn)\n",
    "parameter_array_all[:, 3] = np.log10(parameter_array_all[:, 3])\n",
    "\n",
    "parameter_array_unscaled = np.loadtxt(paramIn)\n",
    "# parameter_array_unscaled[:, 3] = np.log10(parameter_array_unscaled[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadFile = np.loadtxt(fileIn)\n",
    "# PmPl_all = loadFile[:, 1:].T\n",
    "# kvals = loadFile[:,0]\n",
    "\n",
    "\n",
    "# parameter_array_all = np.loadtxt(paramIn)\n",
    "# parameter_array_unscaled = np.loadtxt(paramIn)\n",
    "\n",
    "\n",
    "############## rescaling ##############\n",
    "\n",
    "\n",
    "def rescale01(f):\n",
    "    return np.min(f), np.max(f), (f - np.min(f)) / (np.max(f) - np.min(f))\n",
    "\n",
    "\n",
    "def scale01(fmin, fmax, f):\n",
    "    return (f - fmin) / (fmax - fmin)\n",
    "#     return f*(fmax - fmin) + fmin\n",
    "\n",
    "\n",
    "lhd = np.zeros_like(parameter_array_all)\n",
    "lhdmin = np.zeros_like(parameter_array_all[1])\n",
    "lhdmax = np.zeros_like(parameter_array_all[1])\n",
    "\n",
    "for i in range(parameter_array_all.shape[1]):\n",
    "    lhdmin[i], lhdmax[i], lhd[:, i] = rescale01(parameter_array_all[:, i])\n",
    "   \n",
    "\n",
    "parameter_array_all = lhd\n",
    "\n",
    "# _,_,PmPl_all = rescale01(loadFile[:, 1:].T)\n",
    "\n",
    "############## rescaling ##############\n",
    "\n",
    "\n",
    "## Removing hold-out test points\n",
    "parameter_array = np.delete(parameter_array_all, del_idx, axis=0)\n",
    "PmPl = np.delete(PmPl_all, del_idx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhdmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# Plot the input parameter distribution ##############################\n",
    "\n",
    "allLabels = [r'${\\Omega}_m$', r'$n_s$', r'${\\sigma}_8$', r'$f_{R_0}$', r'$n$']\n",
    "\n",
    "# def rescale01(f):\n",
    "#     return (f - np.min(f)) / (np.max(f) - np.min(f))\n",
    "\n",
    "# lhd = np.zeros_like(parameter_array_all)\n",
    "# for i in range(parameter_array_all.shape[1]):\n",
    "#     _, _, lhd[:, i] = rescale01(parameter_array_all[:, i])\n",
    "    \n",
    "def plot_params(lhd):\n",
    "    f, a = plt.subplots(lhd.shape[1], lhd.shape[1], sharex=True, sharey=True, figsize=(12, 10) )\n",
    "    plt.suptitle('latin hypercube design (rescaled parameters)', fontsize = 24)\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=None)\n",
    "    plt.rcParams.update({'font.size': 8})\n",
    "\n",
    "    for i in range(lhd.shape[1]):\n",
    "        for j in range(i + 1):\n",
    "            if (i != j):\n",
    "                a[i, j].scatter(lhd[:, i], lhd[:, j], s=5)\n",
    "                a[i, j].grid(True)\n",
    "                \n",
    "#             if (j > i):\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                hist, bin_edges = np.histogram(lhd[:, i], density=True, bins=64)\n",
    "                a[i, i].text(0.4, 0.4, allLabels[i], size = 'xx-large')\n",
    "\n",
    "                a[i, i].bar(bin_edges[:-1], hist / hist.max(), width=0.2, alpha = 0.1)\n",
    "\n",
    "    for i in range(lhd.shape[1]):\n",
    "        for j in range(i + 1, lhd.shape[1]):\n",
    "\n",
    "            plt.delaxes(a[i][j])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_params(lhd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################### PCA ###################################\n",
    "# def PCA_decomp():\n",
    "# #     Dicekriging = importr('DiceKriging')\n",
    "#     r('require(foreach)')\n",
    "#     ro.r.assign(\"nrankmax\", nRankMax)\n",
    "#     r('svd(y_train2)')\n",
    "#     r('svd_decomp2 <- svd(y_train2)')\n",
    "#     r('svd_weights2 <- svd_decomp2$u[, 1:nrankmax] %*% diag(svd_decomp2$d[1:nrankmax])')\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # r('install.packages(\"DiceKriging\")')\n",
    "# Dicekriging = importr('DiceKriging')\n",
    "# Dicekriging = importr('emoa')\n",
    "# GPareto = importr('GPareto')\n",
    "# # r('remove.packages(\"GPareto\")')\n",
    "# # r('install.packages(\"GPareto\")')\n",
    "\n",
    "# r('install.packages(\"GPareto\", dependencies=TRUE, repos=\"https://cloud.r-project.org\")')\n",
    "\n",
    "# r('install.packages(\"DiceDesign\")')\n",
    "# r('install.packages(\"pbivnorm\")')\n",
    "# r('install.packages(\"rgenoud\")')\n",
    "# r('install.packages(\"rgenoud\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### PCA ###################################\n",
    "# set up pca compression\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def PCA_compress(x, nComp):\n",
    "    # x is in shape (nCosmology, nbins)\n",
    "    pca_model = PCA(n_components=nComp)\n",
    "    principalComponents = pca_model.fit_transform(x)\n",
    "    pca_bases = pca_model.components_\n",
    "\n",
    "    print(\"original shape:   \", x.shape)\n",
    "    print(\"transformed shape:\", principalComponents.shape)\n",
    "    print(\"bases shape:\", pca_bases.shape)\n",
    "\n",
    "    import pickle\n",
    "    pickle.dump(pca_model, open(modelDir + 'GPy_PCA_model' + str(nRankMax), 'wb'))\n",
    "\n",
    "    return pca_model, np.array(principalComponents), np.array(pca_bases)\n",
    "\n",
    "\n",
    "######################## GP FITTING ################################\n",
    "\n",
    "## Build GP models\n",
    "# This is evaluated only once for the file name. GP fitting is not required if the file exists.\n",
    "  \n",
    "\n",
    "def GPflow_fit(parameter_array, weights, fname= GPmodel):\n",
    "    kern = gpflow.kernels.Matern52(input_dim = np.shape(parameter_array)[1], ARD=True)\n",
    "#     m1 = GPy.models.GPRegression(parameter_array, weights, kernel=kern)\n",
    "    m = gpflow.models.GPR(parameter_array, weights, kern=kern, mean_function=None)\n",
    "#     print_summary(m)\n",
    "    m.likelihood.variance.assign(0.01)\n",
    "#     m.kern.lengthscales.assign([100, 100, 100, 100, 100])\n",
    "#     m.kern.lengthscales.assign([1, 1, 1, 0.1, 0.1])\n",
    "\n",
    "#     m.kern.lengthscales.assign([0.3, 0.1, 0.2, 0.3, 0.1])\n",
    "    m.kern.lengthscales.assign([25, 65, 15 ,1, 1])\n",
    "\n",
    "\n",
    "#     opt = gpflow.optimizers.Scipy()\n",
    "    \n",
    "    opt = gpflow.train.ScipyOptimizer()\n",
    "    opt.minimize(m)\n",
    "    m.as_pandas_table()\n",
    "    \n",
    "    from pathlib import Path\n",
    "\n",
    "    print(f'GPR lengthscales =', m.kern.lengthscales.value)\n",
    "\n",
    "    \n",
    "    path = Path(GPmodel)\n",
    "    if path.exists():\n",
    "        path.unlink()\n",
    "    \n",
    "    saver = gpflow.saver.Saver()\n",
    "    saver.save(fname + str(nRankMax), m)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## GP PREDICTION FUNCTIONS ###############################\n",
    "\n",
    "\n",
    "def GPy_predict(para_array):\n",
    "    m1p = m1.predict_f(para_array)  # [0] is the mean and [1] the predictive\n",
    "    W_predArray = m1p[0]\n",
    "    W_varArray = m1p[1]\n",
    "    return W_predArray, W_varArray\n",
    "\n",
    "\n",
    "# def Emu(para_array):\n",
    "#     if len(para_array.shape) == 1:\n",
    "#         para_array_rescaled = scale01(lhdmin, lhdmax, para_array)\n",
    "#         W_predArray, _ = GPy_predict(np.expand_dims(para_array_rescaled, axis=0))\n",
    "#         x_decoded = pca_model.inverse_transform(W_predArray)\n",
    "#         return np.squeeze(x_decoded)#[0]\n",
    "\n",
    "def Emu(para_array):\n",
    "    para_array = np.array(para_array)\n",
    "    # print(para_array)\n",
    "    para_array[3] = np.log10(para_array[3])\n",
    "    para_array_rescaled = scale01(lhdmin, lhdmax, para_array)\n",
    "    if len(para_array.shape) == 1:\n",
    "        # print(para_array_rescaled)\n",
    "        W_predArray, _ = GPy_predict(np.expand_dims(para_array_rescaled, axis=0))\n",
    "        x_decoded = pca_model.inverse_transform(W_predArray)\n",
    "        return np.squeeze(x_decoded)#[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######################## GP PREDICTION ###############################\n",
    "\n",
    "# def GP_model_load(GPmodel):\n",
    "#     GPareto = importr('GPareto')\n",
    "\n",
    "#     ro.r('''\n",
    "\n",
    "#     GPmodel <- gsub(\"to\", \"\",''' + GPmodel + ''')\n",
    "\n",
    "#     ''')\n",
    "\n",
    "#     r('''if(file.exists(GPmodel)){\n",
    "#             load(GPmodel)\n",
    "#         }else{\n",
    "#             print(\"ERROR: No trained GP file\")\n",
    "#          }''')\n",
    "#     print('Loaded: ', GPmodel)\n",
    "    \n",
    "    \n",
    "# def GP_predict(para_array):\n",
    "#     GPareto = importr('GPareto')\n",
    "\n",
    "\n",
    "#     para_array = np.expand_dims(para_array, axis=0)\n",
    "#     nr, nc = para_array.shape\n",
    "#     Br = ro.r.matrix(para_array, nrow=nr, ncol=nc)\n",
    "\n",
    "#     ro.r.assign(\"Br\", Br)\n",
    "# #     r('print(\"loaded model in R kernel: \")')\n",
    "# #     r('print(GPmodel)')\n",
    "\n",
    "#     r('wtestsvd2 <- predict_kms(models_svd2, newdata = Br , type = \"UK\")')\n",
    "#     r('reconst_s2 <- t(wtestsvd2$mean) %*% t(svd_decomp2$v[,1:nrankmax])')\n",
    "\n",
    "#     y_recon = np.array(r('reconst_s2'))\n",
    "\n",
    "#     return y_recon[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #################### PCA DECOMPOSITION DONE AGAIN ##############\n",
    "# # Dicekriging = importr('DiceKriging')\n",
    "\n",
    "# PCA_decomp()\n",
    "\n",
    "# #################### LOADING TRAINED GP MODEL ##############\n",
    "\n",
    "# GP_model_load(GPmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GP POSTERIOR DRAWS and PCA RECONSTRUCTIONS ######\n",
    "\n",
    "# m1 = GPy.models.GPRegression.load_model(modelDir + 'GPy_model_rank' +str(nRankMax)+ '.zip')\n",
    "# pca_model = pickle.load(open(modelDir + 'PCA_model_rank'+str(nRankMax), 'rb'))\n",
    "\n",
    "# m1 = GPy.models.GPRegression.load_model(modelDir + 'GPy_model'+ str(nRankMax) +'.zip')\n",
    "# m1 = GPy.models.GPRegression.load_model(GPmodel + '.zip')\n",
    "\n",
    "ctx_for_loading = gpflow.saver.SaverContext(autocompile=False)\n",
    "saver = gpflow.saver.Saver()\n",
    "\n",
    "m1 = saver.load(GPmodel, context=ctx_for_loading)\n",
    "m1.clear()\n",
    "m1.compile()\n",
    "\n",
    "pca_model = pickle.load(open(PCAmodel, 'rb'))\n",
    "\n",
    "# plt.rc('text', usetex=True)  # Slower\n",
    "plt.rc('font', size=18)  # 18 usually\n",
    "\n",
    "plt.figure(999, figsize=(14, 12))\n",
    "from matplotlib import gridspec\n",
    "\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[3, 1])\n",
    "gs.update(hspace=0.02, left=0.2, bottom=0.15)\n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax1 = plt.subplot(gs[1])\n",
    "\n",
    "ax0.set_ylabel(r'$p(x)$', fontsize=25)\n",
    "ax1.set_xlabel(r'$x$', fontsize=25)\n",
    "ax1.set_ylabel(r'$p_{emu}/p_{num} - 1$', fontsize = 18)\n",
    "# ax1.set_ylim(-5e-2, 5e-2)\n",
    "\n",
    "ax0.set_xscale('log')\n",
    "# ax0.set_yscale('log')\n",
    "ax1.set_xscale('log')\n",
    "\n",
    "ax1.axhline(y=0, ls='dashed')\n",
    "\n",
    "color_id = 0\n",
    "for x_id in del_idx:\n",
    "    color_id = color_id + 1\n",
    "    time0 = time.time()\n",
    "#     x_decoded_new = Emu(parameter_array_all[x_id], PCAmodel='PCA_model', GPmodel='GPy_model')\n",
    "    x_decoded_new = Emu(parameter_array_unscaled[x_id])\n",
    "    x_decoded_smooth = scipy.signal.savgol_filter(x_decoded_new , 51, 6)\n",
    "\n",
    "    time1 = time.time()\n",
    "    print('Time per emulation %0.5f' % (time1 - time0), ' s')\n",
    "    ax0.plot(kvals, x_decoded_new, alpha=1.0, lw = 1.5, ls='--', label='emu', dashes=(10, 10), color=plt.cm.Set1(color_id))\n",
    "    ax0.plot(kvals, x_decoded_smooth, alpha=1.0, lw = 1.5, ls='--', label='emu', dashes=(10, 10), color=plt.cm.Set1(color_id))\n",
    "\n",
    "#     x_test = PmPl_all[x_id]\n",
    "    x_test = scipy.signal.savgol_filter(PmPl_all[x_id], 51, 6)\n",
    "\n",
    "    ax0.plot(kvals, x_test, alpha=0.4, label='real', color=plt.cm.Set1(color_id))\n",
    "\n",
    "    ax1.plot(kvals, (x_decoded_smooth / (x_test) ) - 1, ls='--', dashes=(10, 2), color=plt.cm.Set1(color_id))\n",
    "\n",
    "\n",
    "ax0.set_xticklabels([])\n",
    "plt.savefig(plotsDir + 'Pemu_rank' +str(nRankMax) + '.png', figsize=(28, 24), bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GPmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### TESTING ##################################\n",
    "plt.rc('font', size=18)  # \n",
    "\n",
    "PlotPrior = True\n",
    "\n",
    "if PlotPrior:\n",
    "\n",
    "    plt.figure(999, figsize=(14, 12))\n",
    "\n",
    "    gs = gridspec.GridSpec(2, 1, height_ratios=[3, 1])\n",
    "    gs.update(hspace=0.1, left=0.2, bottom=0.15, wspace=0.25)\n",
    "    ax0 = plt.subplot(gs[0])\n",
    "    ax1 = plt.subplot(gs[1])\n",
    "\n",
    "    ax0.set_ylabel(r'$P_{MG}(k)/P_{{\\Lambda}CDM}(k)$',  fontsize = 18)\n",
    "\n",
    "    ax1.set_xlabel(r'$k$[h/Mpc]',  fontsize = 18)\n",
    "    ax1.axhline(y=0, ls='dashed')\n",
    "\n",
    "\n",
    "    ax0.set_yscale('log')\n",
    "    ax0.set_xscale('log')\n",
    "    ax1.set_xscale('log')\n",
    "\n",
    "    ax1.set_ylabel(r'emu/test - 1',  fontsize = 18)\n",
    "    ax1.set_ylim(-5e-2, 5e-2)\n",
    "\n",
    "    ax0.plot(kvals, PmPl_all.T, alpha=0.15, color='k')\n",
    "\n",
    "    start, end = ax0.get_ylim()\n",
    "    ax0.yaxis.set_ticks((np.arange(start, end, 0.1)))\n",
    "    ax0.yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.1f'))\n",
    "    ax1.yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.3f'))\n",
    "\n",
    "\n",
    "    ax0.set_xlim(kvals[0], kvals[-1])\n",
    "    ax1.set_xlim(kvals[0], kvals[-1])\n",
    "    ax0.set_xticklabels([])\n",
    "\n",
    "\n",
    "    color_id = 0\n",
    "    for x_id in del_idx[1:]:\n",
    "        color_id = color_id + 1\n",
    "\n",
    "        time0 = time.time()\n",
    "        x_decodedGPy = Emu(parameter_array_unscaled[x_id])  ## input parameters\n",
    "        time1 = time.time()\n",
    "        print('Time per emulation %0.3f' % (time1 - time0), ' s')\n",
    "        x_test = PmPl_all[x_id]\n",
    "\n",
    "        ax0.plot(kvals, x_decodedGPy, alpha=1.0, ls='--', lw = 1.9, dashes=(5, 5), label='emu', color=plt.cm.Set1(color_id))\n",
    "        ax0.plot(kvals, x_test, alpha=0.7, label='test', color=plt.cm.Set1(color_id))\n",
    "\n",
    "        ax1.plot( kvals, (x_decodedGPy[:]) / (x_test[:])  - 1, color=plt.cm.Set1(color_id))\n",
    "\n",
    "ax0.text(0.07, 1.4, 'z = %0.2f'%z_ID, fontsize= 18, style='italic')\n",
    "\n",
    "plt.savefig(plotsDir + \"Emu.png\",  bbox_inches=\"tight\", dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_decodedGPy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotCls = True\n",
    "\n",
    "if PlotCls:\n",
    "    \n",
    "    numPlots = 5\n",
    "\n",
    "    fig, ax = plt.subplots(5,2, figsize = (15,26))\n",
    "    plt.subplots_adjust(wspace=0.25)\n",
    "    \n",
    "    allMax = np.max(parameter_array_unscaled, axis = 0)\n",
    "    allMin = np.min(parameter_array_unscaled, axis = 0)\n",
    "    allMean = np.mean(parameter_array_unscaled, axis = 0)\n",
    "    Pk_mean = Emu(allMean) \n",
    "    \n",
    "    for paramNo in range(5):\n",
    "        para_range = np.linspace(allMin[paramNo], allMax[paramNo], numPlots)\n",
    "\n",
    "        lines = [\"-\",\"-.\",\"--\",\":\"]\n",
    "        linecycler = cycle(lines)\n",
    "        dashList = [(6,2),(10,1),(5,5),(3,3,2,2),(5,2,20,2)]\n",
    "        colorList = ['r', 'g', 'k', 'b', 'brown']\n",
    "\n",
    "\n",
    "        for plotID in range(numPlots):\n",
    "            para_plot = np.copy(allMean)\n",
    "            para_plot[paramNo] = para_range[plotID]  \n",
    "            x_decodedGPy = Emu(para_plot) \n",
    "            lineObj = ax[4-paramNo,0].plot(kvals, x_decodedGPy, lw= 1.5, linestyle='--', dashes=dashList[plotID], color = colorList[plotID], label = allLabels[paramNo] + ' = %.1e'%para_range[plotID])\n",
    "\n",
    "            ax[4-paramNo,0].set_xscale('log')\n",
    "            ax[4-paramNo,0].set_ylabel(r'$P_{MG}(k)/P_{{\\Lambda}CDM}(k)$')\n",
    "            ax[4-paramNo,0].set_xlabel('$k$[h/Mpc]')\n",
    "            \n",
    "            ax[4-paramNo,0].set_yticks([], minor = True)\n",
    "            ax[4-paramNo,0].legend(iter(lineObj), para_range.round(decimals=2), title = allLabels[paramNo])\n",
    "            ax[4-paramNo,0].legend()\n",
    "\n",
    "            ax[4-paramNo,1].set_xscale('log')\n",
    "            ax[4-paramNo,1].set_ylabel(r'$\\Delta f / f_0$')\n",
    "            ax[4-paramNo,1].set_xlabel('$k$[h/Mpc]')\n",
    "\n",
    "            ax[4-paramNo,1].plot(kvals, (x_decodedGPy)/(Pk_mean) - 1, lw= 1.5, linestyle='--', dashes=dashList[plotID], color = colorList[plotID], label = para_range[plotID] )\n",
    "\n",
    "\n",
    "        start, end = ax[4-paramNo, 0].get_ylim()\n",
    "        ax[4-paramNo, 0].yaxis.set_ticks( (np.arange(start, end, 0.1)))\n",
    "        ax[4-paramNo, 0].yaxis.set_major_formatter(ticker.FormatStrFormatter('%0.1f'))\n",
    "\n",
    "\n",
    "fig.savefig(plotsDir + \"sensitivity.png\",  bbox_inches=\"tight\", dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CALLING THE EMULATOR ##############\n",
    "#### input arguments: (Om, ns, s8, fR0, n)\n",
    "#### output: P_mg/P_lcdm in 20 bins\n",
    "#### Example: \n",
    "\n",
    "# Emu(np.array([0.1, 1.0, 0.8, 3e-5, 1.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#################################################################################################\n",
    "#################################################################################################\n",
    "############################################## MCMC #############################################\n",
    "#################################################################################################\n",
    "\n",
    "import emcee\n",
    "import pygtc\n",
    "\n",
    "#### parameters that define the MCMC\n",
    "\n",
    "ndim = 5\n",
    "nwalkers = 800 #600  # 500\n",
    "nrun_burn = 100  # 50 # 50  # 300\n",
    "nrun = 1000 #700  # 300  # 700\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FAKE DATA GENERATION #####\n",
    "\n",
    "\n",
    "create_fake_fiducial = False\n",
    "\n",
    "if create_fake_fiducial:\n",
    "    dirDataIn = \"./Data/FiducialData/\"\n",
    "\n",
    "    seed = 1\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    Pk_ratio = np.loadtxt(dirDataIn + 'ratios213.txt')[:, 25].T\n",
    "    Pk_ratio = (1 + np.random.rand()/100)*Pk_ratio\n",
    "    np.savetxt(dirDataIn + 'fiducial_ratio213.txt', Pk_ratio)\n",
    "\n",
    "    cov_mat = np.zeros(shape = (Pk_ratio.shape[0], Pk_ratio.shape[0]))\n",
    "\n",
    "    for i in range(Pk_ratio.shape[0]):\n",
    "        cov_mat[i, i] = (1 + kvals[i]**2)*(1 + np.random.rand())*np.sqrt(Pk_ratio[i])/8000\n",
    "\n",
    "    np.savetxt(dirDataIn + 'fiducial_cov213.txt', cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### INTERPOLATED COV MATRIX GENERATION #####\n",
    "\n",
    "\n",
    "create_cov_interpolate = True\n",
    "\n",
    "if create_cov_interpolate:\n",
    "    \n",
    "    ### We have cavariance matrix for 20 bins, convert that to 213\n",
    "        \n",
    "    dirDataIn20 = \"./Data/FiducialData/FromSims/\"\n",
    "    Pk_ratio20 = np.loadtxt(dirDataIn20 + 'ratioavg_97.txt')\n",
    "    cov_mat20 = np.loadtxt(dirDataIn20 + 'covariance_97.txt')\n",
    "\n",
    "\n",
    "    from scipy import interpolate \n",
    "\n",
    "    dataDir20 = \"./Data/Emulator_data/\" ## Data folder\n",
    "    fileIn20 = dataDir20 + 'ratios_' + str(snap_ID) + '.txt'\n",
    "\n",
    "\n",
    "    loadFile20 = np.loadtxt(fileIn20)\n",
    "    kvals20 = loadFile20[:,0]\n",
    "\n",
    "    x = kvals20\n",
    "    y = kvals20\n",
    "    z = cov_mat20\n",
    "\n",
    "    cov_mat_model = interpolate.interp2d(x, y, z, kind='cubic')\n",
    "\n",
    "    xnew = kvals\n",
    "    ynew = kvals\n",
    "\n",
    "    cov_mat213 = cov_mat_model(xnew, ynew)\n",
    "    \n",
    "    cov_mat = cov_mat213\n",
    "    \n",
    "\n",
    "    Pk_ratio_model = interpolate.CubicSpline(kvals20, Pk_ratio20[:, 1])\n",
    "    \n",
    "    Pk_ratio213 = Pk_ratio_model(kvals)\n",
    "    \n",
    "    Pk_ratio = Pk_ratio213\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(232)\n",
    "\n",
    "plt.plot(kvals, Pk_ratio213, 'x')\n",
    "plt.plot(kvals20, Pk_ratio20[:, 1], 'o')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This import registers the 3D projection, but is otherwise unused.\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import numpy as np\n",
    "\n",
    "# %matplotlib notebook\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "# Make data.\n",
    "X = kvals\n",
    "Y = kvals\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = cov_mat\n",
    "\n",
    "# Plot the surface.\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=cm.viridis,\n",
    "                       linewidth=0, antialiased=False, alpha = 0.2)\n",
    "\n",
    "\n",
    "\n",
    "# Make data.\n",
    "X = kvals20\n",
    "Y = kvals20\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = cov_mat20\n",
    "\n",
    "# Plot the surface.\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=cm.inferno,\n",
    "                       linewidth=0, antialiased=False, alpha = 0.4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Customize the z axis.\n",
    "# ax.set_zlim(-1.01, 1.01)\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(surf, shrink=0.8, aspect=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## REAL DATA with ERRORS #############################\n",
    "\n",
    "# Pk_ratio = np.loadtxt(dirDataIn + 'fiducial_ratio213.txt')\n",
    "# cov_mat = np.loadtxt(dirDataIn + 'fiducial_cov213.txt')\n",
    "\n",
    "# dirDataIn = \"./Data/FiducialData/FromSims/\"\n",
    "# Pk_ratio = np.loadtxt(dirDataIn + 'ratioavg_97.txt')\n",
    "# cov_mat = np.loadtxt(dirDataIn + 'covariance_97.txt')\n",
    "\n",
    "# kvals_max = 3.2\n",
    "# kvals_cond = np.where(Pk_ratio < kvals_max)\n",
    "kvals_cond = True\n",
    "\n",
    "x = np.array(kvals)\n",
    "y = Pk_ratio\n",
    "yerr_diag = np.sqrt(np.diag(cov_mat))#[:, 0]\n",
    "\n",
    "\n",
    "\n",
    "# x = x[kvals_cond]\n",
    "# y = y[kvals_cond]\n",
    "\n",
    "yerr_diag = yerr_diag[kvals_cond][0]\n",
    "# emax = emax[ls_cond][:,ls_cond][:,0,:]\n",
    "# cov_mat =  cov_mat[:len(kvals_cond[0]), :len(kvals_cond[0])]\n",
    "## Only works if slicing is done at a corner.\n",
    "# i.e., if ls_cond corresponds to continuous array entries in l\n",
    "# icov = np.linalg.inv(cov_mat)\n",
    "\n",
    "\n",
    "icov = np.linalg.pinv(cov_mat)\n",
    "\n",
    "# Moore-Penrose pseudo-inverse of a matrix.\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pk_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(34, figsize = (8, 6))\n",
    "# np.sqrt(yerr[::5])/Cl[::5]\n",
    "plt.errorbar(x[::], y[::], yerr= yerr_diag[::] , marker='o',\n",
    "       color='k',\n",
    "       ecolor='k',\n",
    "       markerfacecolor='g',\n",
    "       markersize = 2,\n",
    "       capsize=0,\n",
    "       linestyle='None')\n",
    "\n",
    "\n",
    "# plt.plot(kvals, np.loadtxt(dirDataIn + 'ratios213.txt')[:, 1:], alpha = 0.3)\n",
    "plt.plot(kvals, Pk_ratio, alpha = 0.3)\n",
    "# plt.xscale('log')\n",
    "# plt.show()\n",
    "\n",
    "plt.savefig('Plots/PowerSpect_emu.pdf')\n",
    "\n",
    "\n",
    "plt.figure(43, figsize = (7, 6))\n",
    "plt.imshow(cov_mat)\n",
    "plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "plt.savefig('Plots/Cov_mat.pdf')\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kvals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #### Cosmological Parameters ########################################\n",
    "\n",
    "# parameter_array_all.min(axis=0)\n",
    "\n",
    "# para1 = [allLabels[0], 0.1188, 0.12, 0.155]  # Actual 0.119\n",
    "# para2 = [allLabels[1], 0.02230, 0.0215, 0.0235]\n",
    "# para3 = [allLabels[2], 0.8159, 0.7, 0.89]\n",
    "# para4 = [allLabels[3], 0.6774, 0.55, 0.85]\n",
    "# para5 = [allLabels[4], 0.9667, 0.85, 1.05]\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Cosmological Parameters ########################################\n",
    "\n",
    "allMin = parameter_array_unscaled.min(axis=0)\n",
    "allMax = parameter_array_unscaled.max(axis=0)\n",
    "# allMean = parameter_array_all.mean(axis=0)\n",
    "# allMean = parameter_array_all[25]\n",
    "\n",
    "allMean = [0.141745, 0.9667, 0.8159, 1e-5, 1.0]\n",
    "# allMean = [0.141745, 0.9667, 0.8159, -5, 1.0]\n",
    "\n",
    "\n",
    "# Ω_m*h^2=0.141745, n_s=0.9667, σ_8 = 0.8159 and for the MG part f_r0=10^-5 and n=1\n",
    "\n",
    "para1 = [allLabels[0], allMean[0], allMin[0], allMax[0]]  # Actual 0.119\n",
    "para2 = [allLabels[1], allMean[1], allMin[1], allMax[1]]\n",
    "para3 = [allLabels[2], allMean[2], allMin[2], allMax[2]]\n",
    "para4 = [allLabels[3], allMean[3], allMin[3], allMax[3]]\n",
    "para5 = [allLabels[4], allMean[4], allMin[4], allMax[4]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### CHAIN INITIALIZATION ##########################\n",
    "\n",
    "## 2 options\n",
    "\n",
    "Uniform_init = True\n",
    "if Uniform_init:\n",
    "    # Choice 1: chain uniformly distributed in the range of the parameters\n",
    "    pos_min = np.array( [para1[2], para2[2], para3[2], para4[2], para5[2]] )\n",
    "    pos_max = np.array( [para1[3], para2[3], para3[3], para4[3], para5[3]] )\n",
    "    psize = pos_max - pos_min\n",
    "    pos0 = [pos_min + psize * np.random.rand(ndim) for i in range(nwalkers)]\n",
    "\n",
    "True_init = False\n",
    "if True_init:\n",
    "    # Choice 2: chain is initialized in a tight ball around the expected values\n",
    "    pos1 = [[para1[1] * 1.2, para2[1] * 0.8, para3[1] * 0.9, para4[1] * 1.1, para5[1] * 1.2] +\n",
    "            1e-3 * np.random.randn(ndim) for i in range(nwalkers)]\n",
    "\n",
    "MaxLikelihood_init = False\n",
    "if MaxLikelihood_init:\n",
    "    # Choice 2b: Find expected values from max likelihood and use that for chain initialization\n",
    "    # Requires likehood function below to run first\n",
    "\n",
    "    import scipy.optimize as op\n",
    "\n",
    "    nll = lambda *args: -lnlike(*args)\n",
    "    result = op.minimize(nll, [para1[1], para2[1], para3[1], para4[1], para5[1]], args=(x, y, icov))\n",
    "    p1_ml, p2_ml, p3_ml, p4_ml, p5_ml = result[\"x\"]\n",
    "    print(result['x'])\n",
    "\n",
    "    pos0 = [result['x'] + 1e-5 * np.random.randn(ndim) for i in range(nwalkers)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(pos0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pygtc.plotGTC(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the initialization\n",
    "\n",
    "PriorPlot = False\n",
    "\n",
    "if PriorPlot:\n",
    "    fig = pygtc.plotGTC(pos0, labels=[para1[0], para2[0], para3[0], para4[0], para5[0]],\n",
    "                        range=[[para1[2], para1[3]], [para2[2], para2[3]],\n",
    "                               [para3[2], para3[3]],\n",
    "                               [para4[2], para4[3]], [para5[2], para5[3]]],\n",
    "                        truths=[para1[1], para2[1], para3[1], para4[1], para5[1]])\n",
    "    fig.set_size_inches(10, 10)\n",
    "\n",
    "######### not working #######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allMin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1, p2, p3, p4, p5 = allMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (para1[2] < p1 < para1[3] and para2[2] < p2 < para2[3] and para3[2] < p3 < para3[3] and para4[2] < p4 < para4[3] and para5[2] < p5 < para5[3]):\n",
    "        print('Success')\n",
    "print('fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnprior(theta):\n",
    "    p1, p2, p3, p4, p5 = theta\n",
    "    # if 0.12 < p1 < 0.155 and 0.7 < p2 < 0.9:\n",
    "    if (para1[2] < p1 < para1[3] and para2[2] < p2 < para2[3] and para3[2] < p3 < para3[3] and para4[2] < p4 < para4[3] and para5[2] < p5 < para5[3]):\n",
    "        return 0.0\n",
    "    return -np.inf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnprior_gauss(theta):\n",
    "    p1, p2, p3, p4, p5 = theta\n",
    "    #flat priors on b, c\n",
    "#     if not 1.0 < b < 2.0 and 1.0 < c < 2.0:\n",
    "    if not (para4[2] < p4 < para4[3] and para5[2] < p5 < para5[3]):\n",
    "        return -np.inf\n",
    "    #gaussian prior on a\n",
    "    width = 2.0 #0.5\n",
    "    mu_para1 = para1[1]\n",
    "    sigma_para1 = np.abs(para1[2] - para1[3])/4\n",
    "#     lnprior1 =  np.log(1.0/(np.sqrt(2*np.pi)*sigma_para1))-0.5*(p1-mu_para1)**2/sigma_para1**2\n",
    "    lnprior1 =  -width*(p1-mu_para1)**2/sigma_para1**2\n",
    "    \n",
    "        #gaussian prior on d\n",
    "    mu_para2 = para2[1]\n",
    "    sigma_para2 = np.abs(para2[2] - para2[3])/4\n",
    "#     lnprior2 =  np.log(1.0/(np.sqrt(2*np.pi)*sigma_para2))-0.5*(p2-mu_para2)**2/sigma_para2**2\n",
    "    lnprior2 =  -width*(p2-mu_para2)**2/sigma_para2**2\n",
    "    \n",
    "        #gaussian prior on e\n",
    "    mu_para3 = para3[1]\n",
    "    sigma_para3 = np.abs(para3[2] - para3[3])/4\n",
    "#     lnprior3 =  np.log(1.0/(np.sqrt(2*np.pi)*sigma_para3))-0.5*(p3-mu_para3)**2/sigma_para3**2\n",
    "    lnprior3 =  -width*(p3-mu_para3)**2/sigma_para3**2\n",
    "    \n",
    "    return (lnprior1 + lnprior2 + lnprior3)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnprior([0.1, 1.1, 0.8, 3e-5, 1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### TEMPLATE FOR MCMC LIKELIHOOD FUNCTION #######################\n",
    "# For emcee\n",
    "\n",
    "def lnlike_diag(theta, x, y, yerr):\n",
    "    p1, p2, p3, p4, p5 = theta\n",
    "\n",
    "    new_params = np.array([p1, p2, p3, p4, p5])\n",
    "\n",
    "    model = Emu(new_params)\n",
    "    return -0.5 * (np.sum(((y - model) / yerr) ** 2.))\n",
    "#     return -0.5 * (np.sum(((y - model) / yerr) ** 2.))\n",
    "\n",
    "\n",
    "def lnlike_full(theta, x, y, icov):\n",
    "    p1, p2, p3, p4, p5 = theta\n",
    "\n",
    "    new_params = np.array([p1, p2, p3, p4, p5])\n",
    "\n",
    "    model = Emu(new_params)\n",
    "    \n",
    "    y_model = np.asarray(y-model)\n",
    "    icov = np.asarray(icov)\n",
    "    return -0.5*(y_model.dot(icov).dot(y_model))\n",
    "\n",
    "## likelihood with reduced k-values\n",
    "\n",
    "def lnlike(theta, x, y, icov):\n",
    "    p1, p2, p3, p4, p5 = theta\n",
    "    \n",
    "    kval_cut = 1.0\n",
    "    truncated_kvals = np.where(x < kval_cut)\n",
    "    \n",
    "    new_params = np.array([p1, p2, p3, p4, p5])\n",
    "\n",
    "    icov = np.asarray(icov)\n",
    "    \n",
    "    \n",
    "    model = Emu(new_params)\n",
    "    \n",
    "    model_red = model[truncated_kvals]\n",
    "    icov_red = icov[0: np.array(truncated_kvals)[0][-1] + 1, 0: np.array(truncated_kvals)[0][-1] + 1]\n",
    "    x_red = x[truncated_kvals]\n",
    "    y_red = y[truncated_kvals]\n",
    "    \n",
    "    y_model = np.asarray(y_red-model_red)\n",
    "\n",
    "    \n",
    "    loglike = -0.5*(y_model.dot(icov_red).dot(y_model))\n",
    "    return loglike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# def lnprob(theta, x, y, yerr):\n",
    "#     lp = lnprior(theta)\n",
    "#     if not np.isfinite(lp):\n",
    "#         return -np.inf\n",
    "#     # return lp + lnlike_diag(theta, x, y, yerr)\n",
    "#     return lp + lnlike(theta, x, y, yerr)\n",
    "\n",
    "\n",
    "def lnprob(theta, x, y, yerr):\n",
    "    lp = lnprior_gauss(theta)\n",
    "    # lp = lnprior(theta)\n",
    "\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + lnlike_diag(theta, x, y, yerr)\n",
    "    # return lp + lnlike(theta, x, y, yerr)\n",
    "############################# PARAMETERS ##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######### MCMC #######################\n",
    "\n",
    "\n",
    "## Sample implementation :\n",
    "# http://eso-python.github.io/ESOPythonTutorials/ESOPythonDemoDay8_MCMC_with_emcee.html\n",
    "# https://users.obs.carnegiescience.edu/cburns/ipynbs/Emcee.html\n",
    "\n",
    "\n",
    "# Let us setup the emcee Ensemble Sampler\n",
    "# It is very simple: just one, self-explanatory line\n",
    "\n",
    "# sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, args=(x, y, yerr_diag))\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, args=(x, y, icov))\n",
    "\n",
    "###### BURIN-IN #################\n",
    "\n",
    "time0 = time.time()\n",
    "# burnin phase\n",
    "pos, prob, state = sampler.run_mcmc(pos0, nrun_burn)\n",
    "sampler.reset()\n",
    "time1 = time.time()\n",
    "print('burn-in time:', time1 - time0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###### MCMC ##################\n",
    "time0 = time.time()\n",
    "# perform MCMC\n",
    "pos, prob, state = sampler.run_mcmc(pos, nrun)\n",
    "time1 = time.time()\n",
    "print('mcmc time:', time1 - time0)\n",
    "\n",
    "\n",
    "###########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sampler.flatchain\n",
    "samples.shape\n",
    "\n",
    "# samples[:, 3] = np.log10(samples[:, 3])\n",
    "\n",
    "# samples_plot = sampler.chain[:, :, :].reshape((-1, ndim))\n",
    "sampler_chain = sampler.chain[:, :, :]#.reshape((-1, ndim))\n",
    "sampler_chain[:, :, 3] = np.log10(sampler_chain[:, :, 3] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler_chain[:,:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler_chain[:, :, 3] = np.log10(sampler_chain[:, :, 3] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###########################################################################\n",
    "\n",
    "\n",
    "np.savetxt('Data/Chains/SamplerPCA_mcmc_ndim' + str(ndim) + '_nwalk' + str(nwalkers) + '_run' + str(\n",
    "    nrun) + '.txt', sampler_chain.reshape((-1, ndim)))\n",
    "\n",
    "####### FINAL PARAMETER ESTIMATES #######################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "samples_plot = np.loadtxt('Data/Chains/SamplerPCA_mcmc_ndim' + str(ndim) + '_nwalk' + str(\n",
    "    nwalkers) + '_run' + str(nrun) + '.txt')\n",
    "\n",
    "# samples = np.exp(samples)\n",
    "p1_mcmc, p2_mcmc, p3_mcmc, p4_mcmc, p5_mcmc = map(lambda v: (v[1], v[2] - v[1],\n",
    "                                                                               v[1] - v[0]) , zip(*np.percentile(samples_plot, [16, 50, 84], axis=0)))\n",
    "print('mcmc results:', p1_mcmc[0], p2_mcmc[0], p3_mcmc[0], p4_mcmc[0], p5_mcmc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_plot[:,:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### CORNER PLOT ESTIMATES #######################################\n",
    "\n",
    "CornerPlot = True\n",
    "if CornerPlot:\n",
    "    \n",
    "    # priors = ((para1[1], np.abs(para1[2] - para1[3])/4),\n",
    "    #       (para2[1], np.abs(para2[2] - para2[3])/4),\n",
    "    #       (para3[1], np.abs(para3[2] - para3[3])/4),\n",
    "    #       None, None)\n",
    "\n",
    "    width = 0.5\n",
    "    \n",
    "    priors = ((para1[1], width*np.abs(para1[2] - para1[3])),\n",
    "          (para2[1], width*np.abs(para2[2] - para2[3])),\n",
    "          (para3[1], width*np.abs(para3[2] - para3[3])),\n",
    "          None,\n",
    "          None)\n",
    "\n",
    "\n",
    "    fig = pygtc.plotGTC(samples_plot,\n",
    "                        paramNames=[para1[0], para2[0], para3[0], r'$log_{10}($'+para4[0] + r'$)$', para5[0]],\n",
    "                        truths=[para1[1], para2[1], para3[1], np.log10(para4[1]), para5[1]],\n",
    "                        figureSize='MNRAS_page', priors=priors)  # , plotDensity = True, filledPlots = False,\\smoothingKernel = 0, nContourLevels=3)\n",
    "\n",
    "    fig.savefig('Plots/pygtcPCA_' + str(ndim) + '_nwalk' + str(nwalkers) + '_run' + str(\n",
    "        nrun) +  '.pdf')\n",
    "\n",
    "####### FINAL PARAMETER ESTIMATES #######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### CORNER PLOT ESTIMATES #######################################\n",
    "\n",
    "CornerPlot = True\n",
    "if CornerPlot:\n",
    "    width = 0.25\n",
    "    \n",
    "    priors = ((para1[1], width*np.abs(para1[2] - para1[3])),\n",
    "          (para2[1], width*np.abs(para2[2] - para2[3])),\n",
    "          (para3[1], width*np.abs(para3[2] - para3[3])),\n",
    "          None,\n",
    "          None)\n",
    "\n",
    "    fig = pygtc.plotGTC(samples_plot,\n",
    "                        paramNames=[para1[0], para2[0], para3[0], r'$log_{10}($'+para4[0] + r'$)$', para5[0]],\n",
    "                        truths=[para1[1], para2[1], para3[1], np.log10(para4[1]), para5[1]],\n",
    "                        figureSize='MNRAS_page', priors=priors)  # , plotDensity = True, filledPlots = False,\\smoothingKernel = 0, nContourLevels=3)\n",
    "\n",
    "    fig.savefig('Plots/pygtcPCA_' + str(ndim) + '_nwalk' + str(nwalkers) + '_run' + str(\n",
    "        nrun) +  '.pdf')\n",
    "\n",
    "####### FINAL PARAMETER ESTIMATES #######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dPdt(param_idx, step):\n",
    "\n",
    "    step_params = step*fid_params[param_idx]\n",
    "    \n",
    "    para_idx_array = np.zeros_like(fid_params)\n",
    "    para_idx_array[param_idx] = 1\n",
    "    fid_params_l = fid_params + step_params*para_idx_array*fid_params\n",
    "    \n",
    "    model_l = Emu(fid_params_l)\n",
    "    model_l = model_l[truncated_kvals]\n",
    "    \n",
    "    fid_params_r = fid_params - step_params*para_idx_array*fid_params\n",
    "    model_r = Emu(fid_params)  \n",
    "    model_r = model_r[truncated_kvals]\n",
    "\n",
    "    dPdt = (model_r - model_l) / (2.0 * step_params)\n",
    "    return dPdt\n",
    "\n",
    "def fiducial(icov):\n",
    "    step = 0.001\n",
    "#     fid_ij = np.zeros(shape=(fid_params.shape[0], fid_params.shape[0], icov_red.shape[0], icov_red.shape[1]) )\n",
    "    fid_ij = np.zeros(shape=(fid_params.shape[0], fid_params.shape[0] ) )\n",
    "    \n",
    "    for i in range(fid_params.shape[0]):\n",
    "        for j in range(fid_params.shape[0]):\n",
    "#             fid_ij[i, j] = np.dot(dPdt(i, step), np.dot(icov, dPdt(i, step)) )\n",
    "#           fid_ij[i, j] = (dPdt(i, step)*icov_red*dPdt(j, step))\n",
    "#           fid_ij[i, j] = np.dot(np.dot(icov_red,dPdt(i, step)), np.dot(icov_red, dPdt(j, step)))\n",
    "          fid_ij[i, j] = np.dot(dPdt(i, step), np.dot(icov_red, dPdt(j, step)))\n",
    "\n",
    "    \n",
    "#             print(fid_ij.shape)\n",
    "    return fid_ij\n",
    "\n",
    "\n",
    "fid_params = np.array([para1[1], para2[1], para3[1], para4[1], para5[1]])\n",
    "icov = np.asarray(icov)\n",
    "x = np.array(kvals)\n",
    "y = Pk_ratio\n",
    "kval_cut = 1.0\n",
    "truncated_kvals = np.where(x < kval_cut)\n",
    "\n",
    "icov_red = icov[0: np.array(truncated_kvals)[0][-1] + 1, 0: np.array(truncated_kvals)[0][-1] + 1]\n",
    "\n",
    "# import scipy.ndimage as spi\n",
    "# sigma_y = sigma_x = 10\n",
    "# sigma = [sigma_y, sigma_x]\n",
    "# icov_red = spi.filters.gaussian_filter(icov_red, sigma, mode='constant')\n",
    "\n",
    "\n",
    "x_red = x[truncated_kvals]\n",
    "y_red = y[truncated_kvals]\n",
    "\n",
    "fid_ij = fiducial(icov_red)\n",
    "\n",
    "cov_plot = np.linalg.pinv(fid_ij)\n",
    "\n",
    "cov_ij = np.linalg.pinv(fid_ij)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.contourf(cov_ij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import fishchips.util\n",
    "\n",
    "\n",
    "# import scipy.ndimage as spi\n",
    "# sigma_y = sigma_x = 0.01\n",
    "# sigma = [sigma_y, sigma_x]\n",
    "# cov_fid = spi.filters.gaussian_filter(cov, sigma, mode='constant')\n",
    " \n",
    "labels =  allLabels # [r'$\\omega_b$', r'$\\omega_{cdm}$', r'$h$',  r'$A_s$', r'$n_s$', r'$\\tau_{reio}$']\n",
    "pars = np.array(['Omega_m', 'n_s', 'sigma_8', 'f_R_0', 'n'])\n",
    "centers = fid_params #np.array([0.02222,  0.1197,  0.69,  2.1955e-9, 0.9655, 0.06])\n",
    "# fig, axes = fishchips.util.plot_triangle_base(pars, centers, cov, labels=labels)\n",
    "# fig_gtc= pygtc.plotGTC(samples_plot,\n",
    "#                         paramNames=[para1[0], para2[0], para3[0], r'$log_{10}($'+para4[0] + r'$)$', para5[0]],\n",
    "#                         truths=[para1[1], para2[1], para3[1], np.log10(para4[1]), para5[1]],\n",
    "#                         figureSize='MNRAS_page', priors=priors)  # , plotDensity = True, filledPlots = False,\\smoothingKernel = 0, nContourLevels=3)\n",
    "\n",
    "fig, ax = fishchips.util.plot_triangle_base(pars, centers, cov_ij, labels=labels)\n",
    "\n",
    "\n",
    "samples_plot_kde = samples_plot[:5000, :]\n",
    "samples_plot_kde[:, 3] = np.log10(samples_plot_kde[:, 3])\n",
    "\n",
    "import seaborn as sns\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if (i>j):\n",
    "            sns.kdeplot(samples_plot_kde[:, j], samples_plot_kde[:, i], n_levels=100, cmap=\"Reds_d\", shade=True, shade_lowest=False, ax = ax[i, j])\n",
    "\n",
    "plt.savefig('fisher_poterior_compare', dpi=300)\n",
    "\n",
    "# chains = [samples_plot[:, 3], samples_plot[:, 4]]\n",
    "# pygtc.pygtc.__plot2d(ax[0, 0], nChains = len(chains), chains2d=chains, weights= , nBins = , smoothingKernel= )\n",
    "\n",
    "# #sns.plt.show()\n",
    " \n",
    "# import seaborn as sns\n",
    " \n",
    "# # # Basic 2D density plot\n",
    "# sns.set_style(\"white\")\n",
    "# sns.kdeplot(np.array(chains[0])[:1000], np.array(chains[1])[:1000], shade=True) \n",
    "# # # Some features are characteristic of 2D: color palette and wether or not color the lowest range\n",
    "# # # sns.kdeplot(df.sepal_width, df.sepal_length, cmap=\"Blues\", shade=True, shade_lowest=True, )\n",
    "# # plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy import stats\n",
    "X = samples_plot_kde[:, 2]\n",
    "Y = samples_plot_kde[:, 4]\n",
    "values = np.vstack( [X, Y])\n",
    "\n",
    "X_grid, Y_grid = np.mgrid[X.min():X.max():100j, Y.min():Y.max():100j]\n",
    "\n",
    "positions = np.vstack([X_grid.ravel(), Y_grid.ravel()])\n",
    "kernel = stats.gaussian_kde(values)\n",
    "Z = np.reshape(kernel(positions).T, X_grid.shape)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "ax[1, 0].contour(Z)\n",
    "plt.figure(figsize = (8,8))\n",
    "plt.contourf(Z, 10 ) #[0.68, 0.95, 0.997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# X = np.array(chains[0])[:10000]\n",
    "# Y = np.array(chains[1])[:10000]\n",
    "values = np.vstack( [X, Y])\n",
    "\n",
    "X_grid, Y_grid = np.mgrid[X.min():X.max():100j, Y.min():Y.max():100j]\n",
    "\n",
    "positions = np.vstack([X_grid.ravel(), Y_grid.ravel()])\n",
    "kernel = stats.gaussian_kde(values)\n",
    "Z = np.reshape(kernel(positions).T, X_grid.shape)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "ax[1, 0].contour(Z)\n",
    "plt.figure(figsize = (8,8))\n",
    "plt.contourf(Z, 10 ) #[0.68, 0.95, 0.997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(X, Y, n_levels=3, cmap=\"Reds_d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def get_ellipse(par1, par2, params, cov, scale1=1, scale2=1):\n",
    "def get_ellipse(par1, par2, params, cov, scale1=1, scale2=1):\n",
    "    \"\"\"\n",
    "    Extract ellipse parameters from covariance matrix.\n",
    "    Parameters\n",
    "    ----------\n",
    "        par1 (string): name of parameter 1\n",
    "        par2 (string): name of parameter 2\n",
    "        params (list of strings): contains names of parameters to constrain\n",
    "        cov (numpy array): covariance matrix\n",
    "    Return\n",
    "    ------\n",
    "        tuple, ellipse a, b, angle in degrees, sigma_x, sigma_y, sigma_xy\n",
    "    \"\"\"\n",
    "    # equations 1-4 Coe 2009. returns in degrees\n",
    "    # first look up indices of parameters\n",
    "    pind = dict(zip(params, list(range(len(params)))))\n",
    "    i1 = pind[par1]\n",
    "    i2 = pind[par2]\n",
    "    sigma_x2 = cov[i1, i1] * scale1*scale1\n",
    "    sigma_y2 = cov[i2, i2] * scale2*scale2\n",
    "    sigma_xy = cov[i1, i2] * scale1*scale2\n",
    "\n",
    "    if ((sigma_y2/sigma_x2) < 1e-10) or ((sigma_x2/sigma_y2) < 1e-10):\n",
    "        a2 = max(sigma_x2, sigma_y2) + sigma_xy**2 / max(sigma_x2, sigma_y2)\n",
    "        b2 = min(sigma_x2, sigma_y2) - sigma_xy**2 / max(sigma_x2, sigma_y2)\n",
    "    else:\n",
    "        a2 = (sigma_x2+sigma_y2)/2. + np.sqrt((sigma_x2 - sigma_y2)**2/4. + sigma_xy**2)\n",
    "        b2 = (sigma_x2+sigma_y2)/2. - np.sqrt((sigma_x2 - sigma_y2)**2/4. + sigma_xy**2)\n",
    "    angle = np.arctan(2.*sigma_xy/(sigma_x2-sigma_y2)) / 2.\n",
    "    if (sigma_x2 < sigma_y2): a2, b2 = b2, a2\n",
    "\n",
    "    return np.sqrt(a2), np.sqrt(b2), angle*180.0/np.pi, np.sqrt(sigma_x2), np.sqrt(sigma_y2), sigma_xy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "X = np.array(chains[0])[:1000]\n",
    "Y = np.array(chains[1])[:1000]\n",
    "values = np.vstack( [X, Y])\n",
    "\n",
    "X_grid, Y_grid = X, Y = np.mgrid[X.min():X.max():100j, Y.min():Y.max():100j]\n",
    "\n",
    "positions = np.vstack([X.ravel(), Y.ravel()])\n",
    "kernel = stats.gaussian_kde(values)\n",
    "Z = np.reshape(kernel(positions).T, X.shape)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(np.rot90(Z), cmap=plt.cm.gist_earth_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel(values).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(chains[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfits = np.array([p1_mcmc[0], p2_mcmc[0], p3_mcmc[0], 10**(p4_mcmc[0]), p5_mcmc[0]])\n",
    "fid_cosmo = np.array(allMean)\n",
    "\n",
    "plt.figure(3111, figsize = (8, 6))\n",
    "# np.sqrt(yerr[::5])/Cl[::5]\n",
    "plt.errorbar(x[::], y[::], yerr= yerr_diag[::] , marker='o',\n",
    "       color='k',\n",
    "       ecolor='k',\n",
    "       markerfacecolor='g',\n",
    "       markersize = 2,\n",
    "       capsize=0,\n",
    "       linestyle='None', alpha = 0.3, label = 'fiducial cosmology')\n",
    "\n",
    "plt.plot(x[::], Emu(fid_cosmo), label = 'emulated at fiducial cosmology')\n",
    "plt.plot(x[::], Emu(pfits), label = 'emulated at best fit')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import numpy\n",
    "# lnlike([0.1, 1.1, 0.8, 3e-5, 1.5], x, y, yerr_diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnprior([0.1, 1.1, 0.8, 3e-5, 1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[para1[2], para2[2], para3[2], para4[2], para5[2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplerlnprob = (sampler.lnprobability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(2323, figsize = (10,10))\n",
    "plt.plot(samplerlnprob.T)\n",
    "# plt.yscale('symlog')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(23)\n",
    "plt.hist(samplerlnprob[:, -1], 200, alpha = 0.4)\n",
    "plt.hist(samplerlnprob[:, -1][samplerlnprob[:, -1] > -100], 10, alpha = 0.4)\n",
    "# plt.hist(samplerlnprob[:, -1][samplerlnprob[:, -1] > -30], 10, alpha = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### CORNER PLOT ESTIMATES #######################################\n",
    "\n",
    "new_samples = sampler.chain[samplerlnprob[:, -1] > -110][:, :, :].reshape((-1, ndim))\n",
    "\n",
    "\n",
    "CornerPlot = True\n",
    "if CornerPlot:\n",
    "\n",
    "    fig = pygtc.plotGTC(new_samples,\n",
    "                        paramNames=[para1[0], para2[0], para3[0], r'$log_{10}($'+para4[0] + r'$)$', para5[0]],\n",
    "                        truths=[para1[1], para2[1], para3[1], np.log10(para4[1]), para5[1]],\n",
    "                        figureSize='MNRAS_page', nContourLevels = 3)# , plotDensity = True, filledPlots = True,smoothingKernel = 0, nContourLevels= 3)\n",
    "\n",
    "    fig.savefig('Plots/pygtcPCA_' + str(ndim) + '_nwalk' + str(nwalkers) + '_run' + str(\n",
    "        nrun) +  '.pdf')\n",
    "\n",
    "####### FINAL PARAMETER ESTIMATES #######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tau = sampler.get_autocorr_time()\n",
    "# autocorr[index] = np.mean(tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 100*np.arange(1, index+1)\n",
    "y = autocorr[:index]\n",
    "plt.plot(n, n / 100.0, \"--k\")\n",
    "plt.plot(n, y)\n",
    "plt.xlim(0, n.max())\n",
    "plt.ylim(0, y.max() + 0.1*(y.max() - y.min()))\n",
    "plt.xlabel(\"number of steps\")\n",
    "plt.ylabel(r\"mean $\\hat{\\tau}$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the estimators for a few different chain lengths\n",
    "chain = sampler.chain#[:, :, 0].T\n",
    "\n",
    "\n",
    "N = np.exp(np.linspace(np.log(100), np.log(chain.shape[1]), 10)).astype(int)\n",
    "gw2010 = np.empty(len(N))\n",
    "new = np.empty(len(N))\n",
    "for i, n in enumerate(N):\n",
    "    gw2010[i] = autocorr_gw2010(chain[:, :n])\n",
    "    new[i] = autocorr_new(chain[:, :n])\n",
    "\n",
    "# Plot the comparisons\n",
    "plt.loglog(N, gw2010, \"o-\", label=\"G\\&W 2010\")\n",
    "plt.loglog(N, new, \"o-\", label=\"new\")\n",
    "ylim = plt.gca().get_ylim()\n",
    "plt.plot(N, N / 50.0, \"--k\", label=r\"$\\tau = N/50$\")\n",
    "plt.ylim(ylim)\n",
    "plt.xlabel(\"number of samples, $N$\")\n",
    "plt.ylabel(r\"$\\tau$ estimates\")\n",
    "plt.legend(fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bitce3244333c914215a448a19ac9208534"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}